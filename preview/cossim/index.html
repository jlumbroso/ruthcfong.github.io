<!doctype html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script src="https://distill.pub/template.v2.js"></script>
  <!--<script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.9.3/Chart.min.js" integrity="sha256-R4pqcOYV8lt7snxMQO/HSbVCFRPMdrhAFMH+vr9giYI=" crossorigin="anonymous"></script>-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.9.3/Chart.js" integrity="sha256-nZaxPHA2uAaquixjSDX19TmIlbRNCOrf5HO1oHl5p70=" crossorigin="anonymous"></script>
	<script src="https://d3js.org/d3.v5.min.js"></script>
  <style>.subgrid {
  grid-column: screen; 
  display: grid; 
  grid-template-columns: inherit;
  grid-template-rows: inherit;
  grid-column-gap: inherit;
  grid-row-gap: inherit;
}

d-figure.base-grid {
  grid-column: screen;
  background: hsl(0, 0%, 97%);
  padding: 20px 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

d-figure {
  margin-bottom: 1em;
  position: relative;
}

d-figure > figure {
  margin-top: 0;
  margin-bottom: 0;
}

figcaption {
  margin-top: 5px;
  margin-bottom: 5px;
}

.shaded-figure {
  background-color: hsl(0, 0%, 97%);
  border-top: 1px solid hsla(0, 0%, 0%, 0.1);
  border-bottom: 1px solid hsla(0, 0%, 0%, 0.1);
  padding: 30px 0;
}

.pointer {
  position: absolute;
  width: 26px;
  height: 26px;
  top: 26px;
  left: -48px;
}

.collapsible {
  background-color: #777;
  color: white;
  cursor: pointer;
  padding: 18px;
  width: 100%;
  border: none;
  text-align: left;
  outline: none;
  font-size: 15px;
}

.active, .collapsible:hover {
  background-color: #555;
}

/*.content {
  padding: 0 18px;
  display: none;
  overflow: hidden;
  background-color: #f1f1f1;
}*/
</style>
</head>

<body>

<d-front-matter>
  <script type="text/json">{
    "title": "The Building Blocks of Interpretability",
    "description": "Interpretability techniques are normally studied in isolation. We explore the powerful interfaces that arise when you combine them -- and the rich structure of this combinatorial space.",
    "password": "cossim",
    "authors": [
      {
        "author": "Ruth Fong",
        "authorURL": "http://www.ruthfong.com/",
        "affiliation": "Princeton University",
        "affiliationURL": "https://www.princeton.edu/"
      },
      {
        "author": "Alexander Mordvintsev",
        "authorURL": "https://znah.net/",
        "affiliation": "Google Research",
        "affiliationURL": "https://research.google.com/"
      },
      {
        "author": "Andrea Vedaldi",
        "authorURL": "http://www.robots.ox.ac.uk/~vedaldi/",
        "affiliation": "University of Oxford",
        "affiliationURL": "https://www.ox.ac.uk"
      },
      {
        "author": "Chris Olah",
        "authorURL": "https://colah.github.io/",
        "affiliation": "Anthropic",
        "affiliationURL": "https://www.anthropic.com/"
      }
    ],
    "katex": {
      "delimiters": [
        {
          "left": "$",
          "right": "$",
          "display": false
        },
        {
          "left": "$$",
          "right": "$$",
          "display": true
        }
      ]
    }
    }</script>
  <!--<script type="text/json">{
  "title": "Interactive Similarity Overlays",
  "description": "An interactive tool for understanding what neural networks consider similar and different.",
  "password": "cossim",
  "authors": [
    {
      "author": "Ruth Fong",
      "authorURL": "https://www.ruthfong.com/",
      "affiliation": "University of Oxford",
      "affiliationURL": "https://www.ox.ac.uk"
    },
  ],
  }</script>-->
  <!--<script type="text/json">{
  "title": "Interactive Similarity Overlays",
  "description": "An interactive tool for understanding what neural networks consider similar and different.",
  "password": "cossim",
  "authors": [
    {
      "author": "Ruth Fong",
      "authorURL": "https://www.ruthfong.com/",
      "affiliation": "University of Oxford",
      "affiliationURL": "https://www.ox.ac.uk"
    },
    {
      "author": "Andrea Vedaldi",
      "authorURL": "http://www.robots.ox.ac.uk/~vedaldi/",
      "affiliation": "University of Oxford",
      "affiliationURL": "https://www.ox.ac.uk"
    },
    {
      "author": "Alexander Mordvintsev",
      "authorURL": "https://znah.net/",
      "affiliation": "Google AI",
      "affiliationURL": "https://research.google.com/"
    },
    {
      "author": "Chris Olah",
      "authorURL": "https://colah.github.io/",
      "affiliation": "Open AI",
      "affiliationURL": "https://openai.com"
    },
  ],
  "katex": {
    "delimiters": [
      {
        "left": "$",
        "right": "$",
        "display": false
      },
      {
        "left": "$$",
        "right": "$$",
        "display": true
      }
    ]
  }
  }
</script>-->
</d-front-matter>

<d-title style="contain: style; overflow: visible;">
  <h1>Interactive Similarity Overlays</h1>
  <p>An interactive tool for understanding what neural networks consider similar and different.</p>
  <figure class="base-grid" id="splash-figure">
      <div id="multi" style="grid-column: screen; margin: 0 auto;"></div>
      <figcaption style="grid-column: text; text-align:justify;">
        <b>Hover over different parts of the above images</b>.
        This interactive visualization shows how similar (or different) a neural network considers different image patches to the current image patch (highlighted in yellow).
        Try hovering over animal features (e.g., noses, eyes, faces) and background regions.
        <!--<div id="colab-multi" style="text-align: right;"></div>-->
      </figcaption>      
  </figure>
  <!--<div class="l-page" id="vtoc"></div>-->
</d-title>

<d-byline></d-byline>

<d-article>
  <p>As digital technology has evolved over the past few decades, the ways we interact with it has also evolved.
    We have moved from typing on a keyboard and viewing a terminal console, to using a mouse and graphical user interface, to employing a variety of touchscreen gestures and voice commands.
    However, despite the rapid progress in deep learning over the past few years<d-cite key="krizhevsky2012,he2017mask,silver2017mastering,devlin2018bert"></d-cite>, the ways we interact with research artifacts have remained largely unchanged: most visualizations used in research are non-responsive plots, images, and videos.</p>
    <!--
* Lightweight (plug-and-play; works for anything else) + re-useable
* interactive visualization (vs. visual interface, a way to navigate an interface, like TensorFlow)
lots of work on visual interfaces~\cite{X}, black-box access~\cite{X}, pedogogical visualization of one model~\cite{X} -- in contrast, our work is an interactive visualization, white-box access, and easily works with any model.
similar to work on self-similarity feature descriptors~\cite{X}
    -->
  <p>
    In this work, we formalize <b>interactive similarity overlays</b> &mdash; an interactive visualization that highlights how a network "sees" different image patches as similar or different.
    Our method builds off of prior work on interactive visualizations for understanding CNNs<d-cite key="yosinski2015understanding,tensorflow2017neural,olah2018building,carter2019activation,hohman2020summit,hohman2020understanding"></d-cite><d-footnote>
      See <d-cite key="sacha2017you,hohman2018visual"></d-cite> for a survey of visualizations for machine learning and deep learning respectively.
    </d-footnote>
    <d-footnote>
      A number of works use interactivity to navigate a visual interface<d-cite key="abadi2016tensorflow,wexler2019if"></d-cite>, focus on visualizing a single model or dataset deeply for pedogogical purposes<d-cite key="wattenberg2016use,carter2016experiments,hohman2017shapeshop,torralba2017drawnet,smilkov2017direct,norton2017adversarial,kahng2018gan,madsen2019visualizing"></d-cite>, treat a model as a black-box by visualizing model inputs and outputs (not internal components)<d-cite key="webster2017now,pair2017facets,wexler2019if"></d-cite>, and/or explore other kinds of models or feature representations (e.g., GANs<d-cite key="zhu2016generative,kahng2018gan,bau2019semantic"></d-cite>, RNNs<d-cite key="strobelt2017lstmvis,strobelt2018seq,madsen2019visualizing"></d-cite>, etc.<d-cite key="talbot2009ensemblematrix,olah2014visualizing,wattenberg2016use,hohman2019gamut"></d-cite>).
      In contrast, our work is an interactive visualization that can be used to explain the internal representation of any CNN model.
    </d-footnote>
    and self-similarity image descriptors<d-cite key="shechtman2007matching,deselaers2010global,seo2009static,vedaldi2009multiple"></d-cite>.
    We also demonstrate how similarity overlays can be combined with other visualization techniques, such as non-negative matrix factorization and interactive charts, to more richly explore the learned representations of convolutional neural networks (CNNs).
    <!--In contrast to prior work on visual interfaces~\cite{X}, black-box interpretability~\cite{X}, ;-->
    We design our similarity overlays so that they can be easily extended or dropped into the existing workflow of a machine learning researcher.<!-- in a plug-and-play fashion.-->
    <!--<d-footnote>
      We release a lightweight, open-source <a href="https://github.com/ruthcfong/interactive_overlay">package</a> that abstracts away the web development components and can be used to easily generate our visualizations in a <a href="https://colab.research.google.com/">Colab</a> notebook for any Python deep learning framework (e.g., <a href="https://www.tensorflow.org/">Tensorflow</a><d-cite key="abadi2016tensorflow"></d-cite>, <a href="https://pytorch.org/">PyTorch</a><d-cite key="paszke2017automatic"></d-cite>).
    </d-footnote>
  -->
    To that end, we release a lightweight package<d-footnote>
      <a href="https://github.com/ruthcfong/interactive_overlay">github.com/ruthcfong/interactive_overlay</a> 
    </d-footnote>
    that abstracts away the web development aspects of the visualization; with it, researchers can easily generate similarity overlays for any CNN with a Python interface (e.g., TensorFlow<d-cite key="abadi2016tensorflow"></d-cite>, PyTorch<d-cite key="paszke2017automatic"></d-cite>).
  </p>

  <div>
  <p>
    Interactive similarity overlays allow a user to hover over an image patch and visualize how similar (or different) other image patches are in a CNN representation (see right figure).
    More precisely, let $s(\mathbf{z_1}, \mathbf{z_2}): \mathbb{R}^{D} \times \mathbb{R}^{D} \to \mathbb{R}$ be a similarity function
    and let $f_l(\mathbf{x}): \mathbb{R}^{3 \times H \times W} \to \mathbb{R}^{D_l \times H_l \times W_l}$ be a function that takes in an input image and returns a 3D tensor (i.e., a CNN up to layer $l$).
    <d-footnote>
      Unless otherwise stated, we use the cosine similarity function, $s(\mathbf{a}, \mathbf{b}) = \frac{\mathbf{a} \cdot \mathbf{b}}{\lVert \mathbf{a} \rVert \lVert \mathbf{b} \rVert}$, and GoogLeNet's<d-cite key="szegedy2015googlenet"></d-cite> mixed4d layer as $f_l(\mathbf{x})$.
      We chose the cosine similarity function because it is the noramlized dot product of two vectors, which quantifies the angle between them (i.e., it captures the <i>directional</i> similarity of two vectors).
    </d-footnote>
    Now, let $\mathbf{z} = f_l(\mathbf{x})$ and let $\mathbf{z}_{i,j}$ denote the activation at the $(i,j)$-th spatial location in $\mathbf{z}$.
    Then, we visualize the similarity between a given spatial location $(i,j)$ and every other location $(u,v)$, which is given by $s(\mathbf{z}_{i,j}, \mathbf{z}_{u,v})$.
    This yields a simple and intuitive visualization that allows for easy exploration of different phenomena, which we explore in the rest of this article.
  </p>
  <p>
    With this technique, we can compare similarities of spatial locations <i>across</i> images, as shown in the splash figure above.
    Within this set of images, we notice that simple background scenes (e.g., those for the dog and cat, flowers, and bird images) are similarly activated despite being visually different.
    We also observe that a few features, such as eyes, are common across object classes (i.e., different species).
    Taken together, these observations suggest that CNNs are capable of learning broad and flexible semantic concepts.
  </p>
  </div>
  <div class="l-page side">
    <figure>
      <div id="example"></div>
      <figcaption style="width:234px; text-align:justify;"><b>Hover over image.</b>
        The intensity of other patches (lighter denotes more similar) captures the similarity to the highlighted image patch (in yellow).
      </figcaption>
    </figure>
  </div>
  <p>
    This multi-image example also highlights the main benefit of interactive similarity overlays, which is their ability to allow users to digest a complex amount of data in an interpretable way.
    For $N$ images, the full scale of the similarities between all image patches is $\mathcal{O}(N^2 \times H_{l}^2 \times W_{l}^2)$.
    By displaying similarities interactively, we show $\mathcal{O}(N \times H_l \times W_l)$ similarity scores at any given moment, thereby making the data easier to digest.
  </p>
  <p>
  In the rest of the article, we demonstrate the utility of our interactive similarity overlays in several case studies.
  </p>

  <!-- 
    Related works:
    * TensorFlow
    * Summit Visualization
  -->
  
  <!--<h2 id="similarity-metrics">Visualizing Similarity Metrics</h2>-->
  <!--TODO(ruthfong): Add figures -->

  <h2 id="layers">Exploring Different Layers' Representations</h2>

  <p>
  First, we consider how interactive similarity overlays help us explore the representations of <i>different</i> CNN layers.
  </p>
  <p>

  Most prior works have explored layer representations from two perspectives:
  1., by exploring how representations in a layer corresponds with different kinds of semantic concepts <d-cite key="agrawal2014analyzing,zhou2014object,gonzalez2016semantic,bau17network,fong18net2vec"></d-cite>(e.g., low-level concepts like colors and textures to high-level concepts like objects and scenes), and
  2., by visualizing the preferred stimuli of a neuron in specific layers (e.g., activation maximization<d-cite key="simonyan14deep,zeiler2014visualizing,olah2017feature"></d-cite>) or the stimuli that best correspond with a reference activation tensor (e.g., representation inversion<d-cite key="mahendran15understanding"></d-cite>, caricatures <d-cite key="mordvintsev2015inceptionism"></d-cite>).
  The former approach typically requires access to manual annotations that define semantic concepts; these are used to "test" a CNN  representation and is limited by the breadth and quality of annotation.
  The latter approach produces a static visualization that often trades off how interpretable a visualization is with how accurately it explains a CNN.<d-footnote>
    In the case of feature visualizations, interpretability refers to how easily interpretable a visualization is (e.g., some feature visualizations are highly unnatural and are hard to reason about), while fidelity refers to how accurately a visualization explains a given model component (e.g., neuron or activation tensor; some feature visualizations rely on strong priors<d-cite key="dosovitskiy2016generating,nguyen2016synthesizing,nguyen2017plug,ulyanov18deep,mordvintsev2018differentiable"></d-cite> in order to be more interpretable by trading off fidelity). 
    Refer to <d-cite key="olah2017feature"></d-cite> for a discussion of this tradeoff.
  </d-footnote>
  In contrast, our interactive visualization similarity does not require manual annotations.
 <!--  a natural image prior or concept prior (i.e., external dataset).-->
  Furthermore, thanks to its interactive nature, our visualization accurately renders information about activation similarities in an interpretable interface.
  <!-- This allows us to explore hypotheses about network behavior without being biased by priors. -->
  </p>

  <p>
  To compare representations of the same input image at different layers, we compute similarity scores <i>within</i> each layer and <i>synchronize</i> the spatial location being explained across layers (i.e., the highlighted image patch in yellow).
  Using this synchronization trick, we first explore the representation of layers with different spatial resolutions.
  Consistent with some prior work, we find that the earlier layers seem to capture lower-level features like edges while later layers tend to highlight higher-level, semantic features like objects.
  We also notice that the representations of later layers appear more smooth.<d-footnote>
    Neighboring spatial locations possess similar scores in smooth representations.
  </d-footnote>
  </p>
  <!--
    First, by visualizing the same image at different locations in a CNN (e.g., network layers), we demonstrate how our technique can be used to explore and understand model representations at different depths.
  -->
  <!--<figure style="grid-column: screen;" class="shaded-figure">
    <d-figure class="base-grid" id="todo_dfigure"></d-figure>
    <div class="base-grid" style="margin-top: 4px;" >
      <div style="grid-column: text / text;" id="colab-negative"></div>
    </div>
  </figure>-->

  <!--<input type="number" bind:value={pos[0]}>
	<input type="number" bind:value={pos[1]}>
  <Chart {pos} size=224 datasource="chart_data.csv" {ylabels} N=2/>-->
  <!--<figure>
    <div id='line-chart'></div>
  </figure>-->

  <figure class="base-grid shaded-figure">
    <figcaption style="grid-column: kicker;">
      <div id="colab-different_layers"></div>
    </figcaption>
    <d-figure style="grid-column: text-start / page-end;" id="different_layers">
      <figcaption><b>Layers with different spatial resolutions.</b><br></figcaption>
    </d-figure>
    <!--<d-figure style="grid-column: text-start / page-end;">
      <figcaption>Hover.</figcaption>
    </d-figure>-->
  </figure>

  <p>
    We also explore the representation of layers with the same spatial resolution.<d-footnote>
      That is, layers that output tensors of the same spatial dimensions (i.e., $H_l$ and $W_l$).
    </d-footnote>
    In this exploration, we confirm our intuition that layer depth affects both the representational smoothness and semantic-ness.
  </p>

  <figure class="base-grid shaded-figure">
    <figcaption style="grid-column: kicker;">
      <div id="colab-mixed4"></div>
    </figcaption>
    <d-figure style="grid-column: text-start / page-end;" id="mixed4">
      <figcaption><b>Mixed4 Layers.</b></figcaption>
    </d-figure>
  </figure>

  <!--
  <figure>
    <div id="dog_cat_layers"></div>
    <div id="flowers_layers"></div>
    <div id="bowtie_guy_layers"></div>
    <div id="pig_layers"></div>
    <div id="beer_layers"></div>
    <div id="chain_layers"></div>
    <figcaption><b>Different Layers.</b></figcaption>
  </figure>
  <figure>
    <div id="dog_cat_mixed4_layers"></div>
    <div id="flowers_mixed4_layers"></div>
    <div id="bowtie_guy_mixed4_layers"></div>
    <div id="pig_mixed4_layers"></div>
    <div id="beer_mixed4_layers"></div>
    <div id="chain_mixed4_layers"></div>
    <figcaption><b>Mixed4 Layers.</b></figcaption>
  </figure>
-->

  <h2 id="class_similarities">Similarities Across Images</h2>
    <p>
      We can also use our visualization to explore representational similarities across images of the same class.
      One interesting application is to compare correspondences between natural images and generated ones.
      To that effect, we compute similarity scores across several images, including ones generated to be classified as the same object class<d-cite key="white2019shared"></d-cite>.<d-footnote>
        These generated images were constrained by brush strokes and inks to appear like modern art.
        See <d-cite key="white2019shared"></d-cite> for more details about their generation process (the prints are available for purchase <a href="https://dribnet.bigcartel.com/category/perception-engines">here</a>).
      </d-footnote>
      We observe that there seem to be a few correspondences (e.g., awareness of spatial position on an object, such as the handle vs. the nozzle of a blow dryer).
    </p>

    <p>
      To enhance our visualization and suggest a few corresponding features, we combined our similarity overlays with another visualization tool: matrix factorization.
      Matrix factorization factors instances into several groups which best explain the variation in a set.
      In the following example, we use matrix factorization to group activation vectors at different spatial locations (and in different images) into discrete groups.<d-footnote>
        See "Implementation Details" at the end of the article for more information about how this figure was generated.
      </d-footnote>
      By combining these two visualization techniques together, we glean more information about the CNN representations being visualized than if we were to use either technique alone.
      Now, we are able to notice and confirm more interesting correspondences (e.g., the correspondence to abstract strokes in a generated image, such as free black strokes corresponding to cords in the blow dryer example).
    </p>
<!--
    The groups that come out of this factorization will be the atoms of the interface a user works with. Unfortunately, any grouping is inherently a tradeoff between reducing things to human scale and, because any aggregation is lossy, preserving information. Matrix factorization lets us pick what our groupings are optimized for, giving us a better tradeoff than the natural groupings we saw earlier.

The goals of our user interface should influence what we optimize our matrix factorization to prioritize. For example, if we want to prioritize what the network detected, we would want the factorization to fully describe the activations. If we instead wanted to prioritize what would change the network’s behavior, we would want the factorization to fully describe the gradient. Finally, if we want to prioritize what caused the present behavior, we would want the factorization to fully describe the attributions. Of course, we can strike a balance between these three objectives rather than optimizing one to the exclusion of the others.

In the following diagram, we’ve constructed groups that prioritize the activations, by factorizing the activations 3 with non-negative matrix factorization 4  . Notice how the overwhelmingly large number of neurons has been reduced to a small set of groups, concisely summarizing the story of the neural network.
-->

    <figure class="base-grid shaded-figure">
      <figcaption style="grid-column: kicker;">
        <div id="colab-perceptual"></div>
      </figcaption>
      <d-figure style="grid-column: text-start / page-end;" id="perceptual">
        <figcaption><b>Comparison with generated images and matrix factors.</b></figcaption>
      </d-figure>
    </figure>
    <figure>
    <!-- Select 10 images to compute components over (default 4; reduced to 3 if 4 seemed too many); showing 5 + perceptual engine -->
    <!-- Too few/many images that are too visually varied -- hard to get clear components -->
    <!-- Blow dryer: 4 components; black strokes correspond to cord (purple component); nozzle part vs. handle -->
    <!--<div id="blow_dryer_images"></div>
    <div id="blow_dryer_components"></div>-->
    <!-- Cello: 4 components; perceptual engine doesn't correspond to all components (i.e., what I thought would be the "human" corresponds to cello) -->
    <!-- Human = component; body vs. neck/strings as component-->
    <!--<div id="cello_images"></div>
    <div id="cello_components"></div>-->
    <!-- iron: 4 components; the stone age one; the handle sems to correspond to check mark black stroke in perceptual engine -->
    <!-- bottom, middle, handle components + background-->
    <!--<div id="iron_images"></div>
    <div id="iron_components"></div>-->
    <!-- hammerhead: 4 components; top-to-bottom spatial awareness; also inside-outside extremeties -->
    <!--<div id="hammerhead_images"></div>
    <div id="hammerhead_components"></div>-->
    <!-- binoculars: 4 components; different components correspond to three different orientations -->
    <!-- cross marks in perceptual image corresponds to cords possibly -->
    <!--<div id="binoculars_images"></div>
    <div id="binoculars_components"></div>-->
    <!-- cabbage: 3 components; correspond to center and extremity -->
    <!--<div id="cabbage_images"></div>
    <div id="cabbage_components"></div>-->
    <!-- jackolantern: 3 components; correspond to center and extremity (4 components didn't make as much sense) -->
    <!-- spatial awareness top-down (but not side to side for symmetric objects) -->
    <!-- top of the pumpkin corresponds to stem? -->
    <!--<div id="jackolantern_images"></div>
    <div id="jackolantern_components"></div>-->
    <!-- measuring_cup: 4 components; Spatial awareness top-down also shown in components
      Other reference illustration (last image) fairly good as a reference -->
    <!--<div id="measuring_cup_images"></div>
    <div id="measuring_cup_components"></div>-->
    <!-- starfish: 3 components; inside and outside
      crosses might correspond to extremeties (see bottom right cross) -->
    <!--<div id="starfish_images"></div>
    <div id="starfish_components"></div>-->
    <!-- tick: 4 components; Body / head / legs
      Black marks seems to correspond to legs / extremities-->
    <!--<div id="tick_images"></div>
    <div id="tick_components"></div>-->
    <!--<figcaption><b>Perceptual engines.</b></figcaption>-->
  </figure>

  <!--TODO(ruthfong): Add Picker -->
  <!--<div id="StickyPicker" style="grid-column: screen;"></div>-->
  <!--<button class="collapsible">Mixed4a Layers</button>
  <div class="content">
    <figure>
      <div id="dog_cat_mixed4_layers"></div>
      <div id="flowers_mixed4_layers"></div>
      <div id="bowtie_guy_mixed4_layers"></div>
      <div id="pig_mixed4_layers"></div>
      <div id="beer_mixed4_layers"></div>
      <div id="chain_mixed4_layers"></div>
      <figcaption><b>mixed4 layers</b></figcaption>
    </figure>
  </div> 
  <button class="collapsible">Different Layers</button>
  <div class="content"> 
    <figure>
      <div id="dog_cat_layers"></div>
      <div id="flowers_layers"></div>
      <div id="bowtie_guy_layers"></div>
      <div id="pig_layers"></div>
      <div id="beer_layers"></div>
      <div id="chain_layers"></div>
      <figcaption><b>Different Layers.</b></figcaption>
    </figure>
  </div>-->

  <h2 id="transformations">Sensitivity to Geometric Transformations</h2>
    <p>
      In a final example, we demonstrate how our interactive similarity overlays help us explore how sensitive or invariant a representation is to geometric transformations (e.g., rotation, scale). 
      By systematically transforming an image (e.g., by fixed-degree rotation) and visualizing similarity scores across transformed images, we can visually inspect the impact of a given transformation.
      We can also combine our overlays with an interactive chart visualization.
    </p>

    <p>
      In the rotation example, we show a line chart that displays the similarity scores of the highlighted image patch as well as the corresponding patch in the other transformed images.
      By leveraging both visualizations, we can quickly notice that more discriminative and oriented features (e.g., animal nose) are more sensitive to rotation than more texture-based, background features (e.g., grass).
      We also discover rotational sensitivity at image borders; this is likely an artifact from padding the boundaries with zero padding.<d-footnote>
        Highlight a boundary pixel and move inward towards the center of the image; you will notice that the ripple effect in similarity scores shown in the line chart becomes smaller as your cursor moves towards the image center.
        Due to large receptive fields, patches in between the image border and center may still be partially affected by boundary effects.
      </d-footnote>
    </p>

    <p>
      By combining visualizations at different layers of abstraction (e.g., qualitative visualization of similarities across all image patches vs. quantitative visualization of a subset of relevant patches), we demonstrate the utility of combining techniques that operate at different levels of abstraction.<d-footnote>
        See <d-cite key="victor2011"></d-cite> for further discussion on the benefits of combining multiple layers of abstraction.
      </d-footnote>
    </p>


  <figure class="base-grid shaded-figure">
    <figcaption style="grid-column: kicker;">
      <div id="colab-rotate"></div>
    </figcaption>
    <d-figure style="grid-column: text-start / page-end;" id="rotate">
      <figcaption><b>Rotate.</b></figcaption>
    </d-figure>
  </figure>

  <p>
    In the scale example, we observe that the spatial relationship of similarities between different features are preserved across scales (e.g., moving a mouse around in one image generates similar "movements" in other images).
    However, by plotting the similarity scores of the highlighted feature across scales, we see more clearly and quantitatively that similarity scores are somewhat sensitive to large scale changes.
    This seems to be true for both discriminative features and background ones, though texture-based, background features may be less sensitive (e.g., background grass vs. cat nose).
  </p>

  <figure class="base-grid shaded-figure">
    <figcaption style="grid-column: kicker;">
      <div id="colab-scale"></div>
    </figcaption>
    <d-figure style="grid-column: text-start / page-end;" id="scale">
      <figcaption><b>Scale.</b></figcaption>
    </d-figure>
  </figure>

  <h2 id="conclusion">Conclusion</h2>
  <p>
    In summary, we introduce a simple interactive visualization , interactive similarity overlays, which allow a user to investigate the representational similarity of various images.
    Thanks to its interactive nature, our visualization is both interpretable and faithful to the model being explained.
    <!--.: its interactivity allows it to render interpretable (e.g., easy to understand) the similarity scores between image patches, while self-suffiency from needing a prior (e.g., a concept prior or image prior) ensures it accurately explains the model's behavior.
    -->
    We highlighted how our visualization enables the exploration of a few CNN properties as well as how it can be thoughtfully combined with other techniques to yield further insights.
  </p>

  <p>
    With a recent movement towards supporting deep learning in Javascript<d-cite key="smilkov2019tensorflow,magentajs"></d-cite> and machine learning research articles with interactive figures<d-cite key="distill"></d-cite>, we eagerly expect further work on interactive visualizations for understanding CNNs that can be easily combined with existing tools.<d-footnote>
      Currently, there are a few open-source packages (e.g., TensorFlow's <a href="https://github.com/tensorflow/lucid/">Lucid</a> and PyTorch's <a href="https://github.com/pytorch/captum/">Captum</a>)
      that implement several CNN visualization methods and support combining techniques.
    </d-footnote>
    To that end, we also release a small package<d-footnote><a href="https://github.com/ruthcfong/interactive_overlay">github.com/ruthcfong/interactive_overlay</a></d-footnote> that allows anyone to easily use our interactive similarity overlays without needing to know Javascript.
    We hope more work is done to empower machine learning practitioners and researchers to easily explore the behavior of their models.
  </p>
  <!--
  <figure>
    <div id="rotate_dog_cat_images"></div>
    <div id="rotate_flowers_images"></div>
    <div id="rotate_pig_images"></div>
    <div id="rotate_bowtie_guy_images"></div>
    <div id="rotate_beer_images"></div>
    <div id="rotate_chain_images"></div>
    <figcaption><b>Rotation.</b></figcaption>
  </figure>
  -->
  <!--<p>
    Typically, we parameterize the input image as the RGB values of each pixel.
    But that isn’t the only way to parameterize images.
    And, as long as the mapping from parameters to images is differentiable, we can still optimize alternative parameterizations with gradient descent.
  </p>-->

  <!--
  <figure>
    <div id="scale_dog_images"></div>
    <div id="scale_cat_images"></div>
    <figcaption><b>Scale.</b></figcaption>
  </figure>
  -->

  <!--
  <figure class="subgrid">
    <figcaption style="grid-column: kicker">
      <span class="figure-number">Figure 1:</span>
      <span style="hyphens: manual;">As long as an </span>
      <span style="background-color: #FFF1E7; padding-left: 2px; padding-right: 2px;">image para&shy;meter&shy;ization</span>
      <span>is differ&shy;entiable, we can back&shy;propagate</span>
      <span style="white-space: nowrap;">( <img src="diagrams/backprop-arrow.svg" style="width: unset;"/> )</span>
      <span>through it.</span>
    </figcaption>
    <div class="l-body">
      <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 704 131"><defs><path d="M7.66953913,-1.63586524 L71.1282599,10.9756179 C73.4625907,11.4395317 74.2711339,11.8093397 75.0739416,12.3826349 C75.8767493,12.95593 76.4832639,13.6948418 76.8890766,14.593999 C77.2948893,15.4931562 77.5,16.3582745 77.5,18.7382569 L77.5,82.2586192 C77.5,84.6386016 77.2948893,85.5037199 76.8890766,86.4028771 C76.4832639,87.3020343 75.8767493,88.040946 75.0739416,88.6142412 C74.2711339,89.1875364 73.4625907,89.5573444 71.1282599,90.0212581 L7.66953913,102.632741 C4.41939249,103.27866 1.26100756,101.167516 0.615088936,97.9173694 C0.538547831,97.5322283 0.5,97.1405034 0.5,96.7478303 L0.5,4.24904582 C0.5,0.935337323 3.1862915,-1.75095418 6.5,-1.75095418 C6.89267317,-1.75095418 7.28439802,-1.71240635 7.66953913,-1.63586524 Z" id="general-c"></path><filter filterUnits="objectBoundingBox" height="109.8%" id="general-b" width="105.8%" x="-2.9%" y="-4.5%"><feMorphology in="SourceAlpha" operator="dilate" radius=".75" result="shadowSpreadOuter1"></feMorphology><feOffset dy="3" in="shadowSpreadOuter1" result="shadowOffsetOuter1"></feOffset><feComposite in="shadowOffsetOuter1" in2="SourceAlpha" operator="out" result="shadowOffsetOuter1"></feComposite><feColorMatrix in="shadowOffsetOuter1" values="0 0 0 0 0.749019608 0 0 0 0 0.682352941 0 0 0 0 0.639215686 0 0 0 1 0"></feColorMatrix></filter><rect height="36" id="general-e" rx="4" width="100" x=".5"></rect><filter filterUnits="objectBoundingBox" height="120.8%" id="general-d" width="104.5%" x="-2.2%" y="-6.2%"><feMorphology in="SourceAlpha" operator="dilate" radius=".75" result="shadowSpreadOuter1"></feMorphology><feOffset dy="3" in="shadowSpreadOuter1" result="shadowOffsetOuter1"></feOffset><feComposite in="shadowOffsetOuter1" in2="SourceAlpha" operator="out" result="shadowOffsetOuter1"></feComposite><feColorMatrix in="shadowOffsetOuter1" values="0 0 0 0 0.748272747 0 0 0 0 0.682170006 0 0 0 0 0.638101513 0 0 0 1 0"></feColorMatrix></filter><rect height="100" id="general-g" rx="3" width="100" x="287.5" y="12.5"></rect><filter filterUnits="objectBoundingBox" height="106%" id="general-f" width="103%" x="-1.5%" y="-1.5%"><feOffset dy="3" in="SourceAlpha" result="shadowOffsetOuter1"></feOffset><feColorMatrix in="shadowOffsetOuter1" values="0 0 0 0 0.901960784 0 0 0 0 0.901960784 0 0 0 0 0.901960784 0 0 0 1 0"></feColorMatrix></filter><pattern height="100%" id="general-h" width="100%" x="0%"><use transform="scale(.69444)" xlink:href="#general-a"></use></pattern><image height="144" id="general-a" width="144" xlink:href="data:image/jpg;base64,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"></image><rect height="36" id="general-j" rx="4" width="100" x="563.5" y="44.5"></rect><filter filterUnits="objectBoundingBox" height="120.8%" id="general-i" width="104.5%" x="-2.2%" y="-6.2%"><feMorphology in="SourceAlpha" operator="dilate" radius=".75" result="shadowSpreadOuter1"></feMorphology><feOffset dy="3" in="shadowSpreadOuter1" result="shadowOffsetOuter1"></feOffset><feComposite in="shadowOffsetOuter1" in2="SourceAlpha" operator="out" result="shadowOffsetOuter1"></feComposite><feColorMatrix in="shadowOffsetOuter1" values="0 0 0 0 0.9 0 0 0 0 0.9 0 0 0 0 0.9 0 0 0 1 0"></feColorMatrix></filter><path d="M448.669539,10.3641348 L512.12826,22.9756179 C514.462591,23.4395317 515.271134,23.8093397 516.073942,24.3826349 C516.876749,24.95593 517.483264,25.6948418 517.889077,26.593999 C518.294889,27.4931562 518.5,28.3582745 518.5,30.7382569 L518.5,94.2586192 C518.5,96.6386016 518.294889,97.5037199 517.889077,98.4028771 C517.483264,99.3020343 516.876749,100.040946 516.073942,100.614241 C515.271134,101.187536 514.462591,101.557344 512.12826,102.021258 L448.669539,114.632741 C445.419392,115.27866 442.261008,113.167516 441.615089,109.917369 C441.538548,109.532228 441.5,109.140503 441.5,108.74783 L441.5,16.2490458 C441.5,12.9353373 444.186292,10.2490458 447.5,10.2490458 C447.892673,10.2490458 448.284398,10.2875937 448.669539,10.3641348 Z" id="general-l"></path><filter filterUnits="objectBoundingBox" height="109.8%" id="general-k" width="105.8%" x="-2.9%" y="-4.5%"><feMorphology in="SourceAlpha" operator="dilate" radius=".75" result="shadowSpreadOuter1"></feMorphology><feOffset dy="3" in="shadowSpreadOuter1" result="shadowOffsetOuter1"></feOffset><feComposite in="shadowOffsetOuter1" in2="SourceAlpha" operator="out" result="shadowOffsetOuter1"></feComposite><feColorMatrix in="shadowOffsetOuter1" values="0 0 0 0 0.9 0 0 0 0 0.9 0 0 0 0 0.9 0 0 0 1 0"></feColorMatrix></filter></defs><g fill="none" fill-rule="evenodd"><g stroke-linecap="square" transform="matrix(-1 0 0 1 565 53)"><path d="M0.5,18.5 C35.5494527,18.5 16.4674397,9.5 48.5,9.5" stroke="#F60" stroke-dasharray="6 4" stroke-width="2" transform="matrix(1 0 0 -1 0 28)"></path><path d="M0.5,9.5 C35.5494527,9.5 16.4674397,0.5 48.5,0.5" stroke="#495160" stroke-width="1.5"></path></g><rect fill="#FFF1E7" height="125" rx="10" width="243" x=".5" y=".5"></rect><g transform="translate(10 12)"><g stroke-linecap="square" transform="translate(98 41.5)"><path d="M3,18 C38.0494527,18 18.9674397,9 51,9" stroke="#F60" stroke-dasharray="6 4" stroke-width="2" transform="matrix(1 0 0 -1 0 27)"></path><path d="M0,9 C35.0494527,9 15.9674397,0 48,0" stroke="#495160" stroke-width="1.5"></path></g><g transform="translate(146)"><g stroke-linecap="square" transform="matrix(-1 0 0 1 78 0)"><use fill="#000" filter="url(#general-b)" xlink:href="#general-c"></use><use fill="#F2F3F5" stroke="#495160" stroke-width="1.5" xlink:href="#general-c"></use></g><text fill="#323B4C" font-size="13" font-weight="500"><tspan x="11.321" y="55">Mapping</tspan></text></g><g transform="translate(.5 32.5)"><g stroke-linecap="square"><use fill="#000" filter="url(#general-d)" xlink:href="#general-e"></use><use fill="#F2F3F5" stroke="#495160" stroke-width="1.5" xlink:href="#general-e"></use></g><text fill="#323B4C" font-size="13" font-weight="500"><tspan x="14.396" y="22">Parameters</tspan></text></g></g><text fill="#4A4A4A" font-size="13"><tspan x="287.5" y="126.5">image/RGB </tspan><tspan x="287.5" y="143.5">space</tspan></text><g transform="translate(237.138 69.5)"><path d="M10.5,4.5 L50.2246377,4.5" stroke="#F60" stroke-dasharray="6 4" stroke-linecap="square" stroke-width="2"></path><path d="M4.5,0 C5.67007294,3.25202425 6.85281213,6.29180565 9,9 L4.5,7.3125 L0,9 C2.13530145,6.28972675 3.34126793,3.24998975 4.5,0 Z" fill="#F60" fill-rule="nonzero" transform="matrix(0 1 1 0 .5 0)"></path></g><g transform="translate(233.5 49.5)"><path d="M50,9 L45.5,7.3125 L41,9 C43.1353015,6.28972675 44.3412679,3.24998975 45.5,0 C46.6700729,3.25202425 47.8528121,6.29180565 50,9 Z" fill="#495160" fill-rule="nonzero" transform="rotate(90 45.5 4.5)"></path><path d="M0,4.5 L43,4.5" stroke="#495160" stroke-linecap="square" stroke-width="1.5"></path></g><use fill="#000" filter="url(#general-f)" xlink:href="#general-g"></use><use fill="url(#general-h)" xlink:href="#general-g"></use><path d="M563.5,71.5 C598.549453,71.5 579.46744,62.5 611.5,62.5" stroke="#F60" stroke-dasharray="6 4" stroke-linecap="square" stroke-width="2" transform="matrix(1 0 0 -1 0 134)"></path><path d="M563.5,62.5 C598.549453,62.5 579.46744,53.5 611.5,53.5" stroke="#495160" stroke-linecap="square" stroke-width="1.5"></path><g stroke-linecap="square"><use fill="#000" filter="url(#general-i)" xlink:href="#general-j"></use><use fill="#F2F3F5" stroke="#495160" stroke-width="1.5" xlink:href="#general-j"></use></g><text fill="#323B4C" font-size="13" font-weight="500"><tspan x="598.799" y="67.5">Loss</tspan></text><g transform="translate(387.5 47.5)"><path d="M50,9 L45.5,7.3125 L41,9 C43.1353015,6.28972675 44.3412679,3.24998975 45.5,0 C46.6700729,3.25202425 47.8528121,6.29180565 50,9 Z" fill="#495160" fill-rule="nonzero" transform="rotate(90 45.5 4.5)"></path><path d="M0,4.5 L43,4.5" stroke="#495160" stroke-linecap="square" stroke-width="1.5"></path></g><g transform="translate(392.138 67.5)"><path d="M10.5,4.5 L50.2246377,4.5" stroke="#F60" stroke-dasharray="6 4" stroke-linecap="square" stroke-width="2"></path><path d="M4.5,0 C5.67007294,3.25202425 6.85281213,6.29180565 9,9 L4.5,7.3125 L0,9 C2.13530145,6.28972675 3.34126793,3.24998975 4.5,0 Z" fill="#F60" fill-rule="nonzero" transform="matrix(0 1 1 0 .5 0)"></path></g><g stroke-linecap="square"><use fill="#000" filter="url(#general-k)" xlink:href="#general-l"></use><use fill="#F2F3F5" stroke="#495160" stroke-width="1.5" xlink:href="#general-l"></use></g><text fill="#323B4C" font-size="13" font-weight="500"><tspan x="452.153" y="66.5">Function</tspan></text></g></svg>
    </div>
  </figure>

  <p>
    Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.
    <d-footnote>Test! Let's cite<d-cite key="gatys2015"></d-cite> someone!</d-footnote>
    More text!
  </p> 
-->

</d-article>



<d-appendix>
  <h3>Additional Resources</h3>
  <p>
    <a href="https://github.com/ruthcfong/interactive_overlay"><b>Code:</b> ruthcfong/interactive_overlay</a>
    <br>
    Open-source implementation of our techniques on GitHub.
  </p>
  <p>
    <strong>Notebooks:</strong>
    <br>
    Direct links to <code>ipynb</code> notebooks corresponding to the respective sections of this paper.
    <ul style="margin: 0 0 0 30px; padding: 0;">
      <li style="margin-bottom: 0.25em;"><a href="https://colab.research.google.com/drive/1QmiesgtgeKQ8ZBHW85VpQIWfqOoB3Oh8?usp=sharing">Basic Examples (TensorFlow)</a></li>
      <li style="margin-bottom: 0.25em;"><a href="https://colab.research.google.com/drive/1d3PLTH9-5A1Ncipysv54XSzZKRiG1fcq?usp=sharing">Class Similarities & Perceptual Engines (TensorFlow)</a></li>
      <li style="margin-bottom: 0.25em;"><a href="https://colab.research.google.com/drive/173RUM_2oRR1JTGAKEbCTanXlAnJ5fvlz?usp=sharing">Geometric Transformations (TensorFlow)</a></li>
    </ul>
  </p>
  <p>
    <strong>Further Notebook:</strong>
    <br>
    Direct link to an <code>ipynb</code> notebook demonstrating how to use our interactive similarity overlays in other applications using PyTorch.
    <ul style="margin: 0 0 0 30px; padding: 0;">
      <li style="margin-bottom: 0.25em;"><a href="https://colab.research.google.com/drive/1o20OXK5SD9NWwYv-duH95fdMDrm5QpEh?usp=sharing"> Comparing Architectures and Supervision (PyTorch)</a></li>
    </ul>
  </p>
  <h3>Acknowledgments</h3>
    <p>
      We are deeply grateful to the following people for helpful conversations: Tom White, David Bau, Been Kim, Xu Ji, Sam Albanie, Mandela Patrick, Ludwig Schubert, Gabriel Goh, and Nick Cammarata.
      We are also thankful to the discussion groups organized by Xu Ji within the VGG group and organized by Chris Olah within the Distill Slack workspace.
      We are also particularly grateful to Tom White for his permission to use his "Perceptual Engines" generated images<d-cite key="white2019shared"></d-cite> and to Been Kim for open-sourcing the Gestalt dataset<d-cite key="kim2019neural"></d-cite> for this project.
      On the Distill side, we are especially grateful to Ludwig Schubert for his Javascript debugging expertise.
    </p>

  <p>
    Lastly, this work was made possible by many open source tools, for which we are grateful.
    In particular, all of our experiments were based on <a href="https://www.tensorflow.org/">Tensorflow</a><d-cite key="abadi2016tensorflow"></d-cite>, <a href="https://pytorch.org/">PyTorch</a><d-cite key="paszke2017automatic"></d-cite>, and <a href="https://github.com/tensorflow/lucid/">Lucid</a>.
    We built our interactive visualizations using <a href="https://svelte.technology/">Svelte</a> and <a href="https://www.chartjs.org/">Chart.js</a>.
    We make our results reproducible using <a href="https://colab.research.google.com/">Colab</a> notebooks.
  </p>

  <h3>Author Contributions</h3>
  <p>
    <b>Research:</b> Alex came up with the initial idea of cosine similarity overlays.
    Ruth developed its applications to interrogate different layers, geometric transformations, etc.
    Andrea and Chris suggested helpful research directions; in particular, Chris suggested combining similarity overlays with other visualization techniques.
  </p>

  <p>
    <b>Writing & Diagrams:</b> The text was initially drafted by Ruth and refined by the other authors.
    The interactive diagrams were designed by all authors.
    The final notebooks were primarily created by Ruth, based on earlier code and notebooks by Alex and Chris.
  </p>

  <h3>Implementation Details</h3>
  <p>
    <b>General:</b>
    Unless otherwise stated, we use the cosine similarity function, $s(\mathbf{a}, \mathbf{b}) = \frac{\mathbf{a} \cdot \mathbf{b}}{\lVert \mathbf{a} \rVert \lVert \mathbf{b} \rVert}$ as the similarity function with which we compute overlays and visualize GoogLeNet's<d-cite key="szegedy2015googlenet"></d-cite> mixed4d layer as $f_l(\mathbf{x})$.
  </p>
  <p>
    <b>Non-negative matrix factorization (NNMF):</b>
    For each object class (e.g., blow dryer), 10 (out of 50) real images from the ImageNet<d-cite key="russakovsky2015imagenet"></d-cite> validation set for that class were selected.
    NNMF was computed on the set of 11 images (10 real images and 1 generated image<d-cite key="white2019shared"></d-cite>).
    By default, 4 components were computed; upon visual inspection, this was reduced to 3 for a few object classes.
    We found that 10 real images was an ideal number of images to use to compute salient components and chose images were somewhat visual similar to one another (e.g., simple backgrounds for blow dryer example).
    We then selected 5 of the 10 real images to be shown in the figure.
  </p>
  <d-footnote-list></d-footnote-list>
  <d-citation-list></d-citation-list>
</d-appendix>

<!-- bibliography will be inlined during Distill pipeline's pre-rendering -->
<d-bibliography src="bibliography.bib"></d-bibliography>

<script type="text/javascript" src="index.bundle.js"></script></body>
